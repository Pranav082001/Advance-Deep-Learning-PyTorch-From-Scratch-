{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIgMwIcEjq3"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from PIL import Image\r\n",
        "import torchvision.transforms as transforms \r\n",
        "import torchvision.models as models\r\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY1P2a-EFVeX"
      },
      "source": [
        "  model=models.vgg19(pretrained=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN2u_DHTFVb2",
        "outputId": "cb6446b6-0704-4c16-c5d8-a6815129ecd3"
      },
      "source": [
        "model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFuJvH2fFVZK"
      },
      "source": [
        "class VGG(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "      super(VGG,self).__init__()\r\n",
        "      self.choosen_features =['0','5','10','19','28']\r\n",
        "      self.model =models.vgg19(pretrained=True).features[:29]\r\n",
        "    \r\n",
        "    def forward(self,x):\r\n",
        "      features=[]\r\n",
        "      for layer_num,layer in enumerate(self.model):\r\n",
        "          x=layer(x)\r\n",
        "\r\n",
        "          if str(layer_num) in self.choosen_features:\r\n",
        "            features.append(x)\r\n",
        "      return features"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg4FBRHZIBRe"
      },
      "source": [
        "def load_image (image_name):\r\n",
        "  image=Image.open(image_name)\r\n",
        "  image=loader(image).unsqueeze(0)\r\n",
        "\r\n",
        "  return image.to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ9yXJX8ILtx"
      },
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "image_size=356\r\n",
        "loader= transforms.Compose ([\r\n",
        "                    transforms.Resize((image_size,image_size)),\r\n",
        "                    transforms.ToTensor()\r\n",
        "                          ])\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyKC44J1KTQ1"
      },
      "source": [
        "original_img=load_image(r\"/content/pp.jpeg\")\r\n",
        "style_img=load_image(r\"/content/style_4.jpg\")\r\n",
        "model= VGG().to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR74wKBtK_mq"
      },
      "source": [
        "#generated =torch.randn(original_img.shape ,device=device,requires_grad=True)\r\n",
        "generated =original_img.clone().requires_grad_(True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwC4r2QGLVTx",
        "outputId": "c313ae96-cba6-4f00-9012-f82991132861"
      },
      "source": [
        "%%time\r\n",
        "total_steps=6000\r\n",
        "learning_rate =0.001\r\n",
        "alpha =1\r\n",
        "beta=0.01\r\n",
        "\r\n",
        "optimizer=optim.Adam([generated], lr=learning_rate)\r\n",
        "\r\n",
        "for step in range(total_steps):\r\n",
        "    generated_features= model(generated)\r\n",
        "    original_img_features = model(original_img)\r\n",
        "    style_features =model(style_img)\r\n",
        "\r\n",
        "    style_loss=original_loss=0\r\n",
        "\r\n",
        "    for gen_feature ,orig_feature,style_feature in zip(\r\n",
        "        generated_features, original_img_features, style_features ):\r\n",
        "      \r\n",
        "              batch_size,channel,height,width=gen_feature.shape\r\n",
        "\r\n",
        "              original_loss +=torch.mean((gen_feature - orig_feature)**2)\r\n",
        "\r\n",
        "              G= gen_feature.view(channel,height*width).mm(\r\n",
        "                  gen_feature.view(channel,height*width).t()\r\n",
        "              )\r\n",
        "\r\n",
        "              A=style_feature.view(channel,height*width).mm(\r\n",
        "                  style_feature.view(channel,height*width).t()\r\n",
        "              )\r\n",
        "              style_loss +=torch.mean((G-A)**2)\r\n",
        "\r\n",
        "    total_loss= alpha* original_loss + beta *style_loss\r\n",
        "    optimizer.zero_grad()\r\n",
        "    total_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if step% 200 ==0:\r\n",
        "        print(total_loss)\r\n",
        "        save_image(generated,\"generated.png\")\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(164396.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8771.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3776.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2362.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1844.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1557.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1356.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1202.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1076.7419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(971.4896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(882.4050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(805.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(737.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(677.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(624.3973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(577.0915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(534.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(496.9010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(463.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(432.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(405.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(380.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(358.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(339.1969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(321.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(305.8719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(291.7505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(279.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(268.0324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(258.1860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "CPU times: user 9min 52s, sys: 8min 25s, total: 18min 18s\n",
            "Wall time: 18min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65oYQuDUQz_M"
      },
      "source": [
        "# for step in range(total_steps):\r\n",
        "#     # Obtain the convolution features in specifically chosen layers\r\n",
        "#     generated_features = model(generated)\r\n",
        "#     original_img_features = model(original_img)\r\n",
        "#     style_features = model(style_img)\r\n",
        "\r\n",
        "#     # Loss is 0 initially\r\n",
        "#     style_loss = original_loss = 0\r\n",
        "\r\n",
        "#     # iterate through all the features for the chosen layers\r\n",
        "#     for gen_feature, orig_feature, style_feature in zip(\r\n",
        "#         generated_features, original_img_features, style_features\r\n",
        "#     ):\r\n",
        "\r\n",
        "#         # batch_size will just be 1\r\n",
        "#         batch_size, channel, height, width = gen_feature.shape\r\n",
        "#         original_loss += torch.mean((gen_feature - orig_feature) ** 2)\r\n",
        "#         # Compute Gram Matrix of generated\r\n",
        "#         G = gen_feature.view(channel, height * width).mm(\r\n",
        "#             gen_feature.view(channel, height * width).t()\r\n",
        "#         )\r\n",
        "#         # Compute Gram Matrix of Style\r\n",
        "#         A = style_feature.view(channel, height * width).mm(\r\n",
        "#             style_feature.view(channel, height * width).t()\r\n",
        "#         )\r\n",
        "#         style_loss += torch.mean((G - A) ** 2)\r\n",
        "\r\n",
        "#     total_loss = alpha * original_loss + beta * style_loss\r\n",
        "#     optimizer.zero_grad()\r\n",
        "#     total_loss.backward()\r\n",
        "#     optimizer.step()\r\n",
        "\r\n",
        "#     if step % 200 == 0:\r\n",
        "#         print(total_loss)\r\n",
        "#         save_image(generated, \"generated.png\")"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}